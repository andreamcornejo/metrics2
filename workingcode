# import and prepare data
GDPSERIES <- read.csv("GDP.csv",header=T)[-1:-4,]         #in order to start both the series in the same year

## Univariate Analysis
# Data Presentation

GDPSERIES$DATE<- NULL              #to remove the date coloum and only specify it as a series of data anf use frequency.
GDPTIMESERIES<-ts(GDPSERIES ,frequency = 4,start = c(1948,1))
autoplot(GDPTIMESERIES, ts.colour = 'red',ylab = "GDP (Billion dollars)",xlab = "Time")


GDPTIMESERIEScomponents <- decompose(GDPTIMESERIES)   #to decompose into seasonal, trend and irregular components of the time series

GDPTIMESERIEScomponents$seasonal
GDPTIMESERIEScomponents$trend       #to view the estimated values stored in these coloums
GDPTIMESERIEScomponents$random
plot(GDPTIMESERIEScomponents) #to view the differnet components graphically

#taking log, to compress huge changes in the variances
logGDP<-log(GDPTIMESERIES)

#however we still have trend which will be proven by the acf of logGDP










GDPTIMESERIESseasonallytrendadjusted <- GDPTIMESERIES  - GDPTIMESERIEScomponents$trend
GDPadjusted <- na.omit(GDPTIMESERIESseasonallytrendadjusted)
autoplot(GDPadjusted, ylab = "GDP Trend Adjusted (Billion dollars)",xlab = "Time")
acf(GDPadjusted)
# Unit root and stationarity test

adf.test(GDPadjusted)            #reject hypothesis that serie is non stationary, implies stationarity
PP.test(GDPadjusted)             # the adf and pp test are unit root tests, rejecting it implies rej H_o=non stationary, which is what we need
kpss.test(GDPadjusted)           #here hypothesis is h_o= stationary. small p value suggests we reject null, serie is non stationary according to this
                                 #Case 2: Unit root test: Reject ð» 0  KPSS test: don`t reject ð»0.  Both imply that series is stationary.
#o                                 ur serie is sttrend ationary



#Finding acf and pacf



#========================================================
# Part II. Multivariate model
#========================================================


## import and prepare data
gdp <- read.csv(file.path("/Users/andreamcornejo/Dropbox/PSE/metrics_2/final project/data/GDP_stlouis_fdreserve.csv"))
un <- read.csv(file.path("/Users/andreamcornejo/Dropbox/PSE/metrics_2/final project/data/unemployment_stlouis_fdreserve_SEASON_ADJ.csv"))
gdp <- gdp[-c(1, 2, 3, 4), ]

#data set BOTH SERIES COMBINED
df <- data.frame(gdp=gdp$GDP, un=un$UNRATE, date=un$DATE)

# format data as time series
df$date<- NULL              #to remove the date column and only specify it as a series of data anf use frequency.
dfts<-ts(df,frequency = 4,start = c(1948,1))


#========================================================
# i. Selection of the lag order of the multivariate model
#========================================================

lags <- VARselect(dfts, lag.max=12) # BIC --> 2, HQ --> 2, AIC/FPE --> 4
print(lags)

There is no one single test or method to determine the lag order of bivariate models. Using VARselect, we see
The Schwrz Bayes info criteria (SC) yields 2, while Akaike AIC gives 4. However, for both of these, the difference
between order 2 and 4 is not much. In this context, we will move forward with lag order 2 for simplicity. 

#========================================================
# ii. Estimation of the multivariate model
#========================================================

VAR2 = VAR(dfts, p=2)
summary(VAR2)       ## this code works

xtable:: xtable(VAR2$varresult$gpd)
xtable:: xtable(VAR2$varresult$un)

This seems to be a good fit, as all coefficients of the estimated model are significant at the alpha= 0.05 level, including the constant and the last lag (2). 
#========================================================
# ii. quality checks
#========================================================

To check the quality of our estimated model, we can use a LjungBox test:
  
LjungBox(VAR2, lags=1:12)

The p-vale for the lag of order 2 has the most significant p-value, with lag4 being the second most significant (consistent with results above). 



We can also use a normality test to check if distribution of residuals is normal: 
  
  normality.test(VAR2) 

##CHECK THIS!
The normality test tells us the we could reject the null hypothesis of normal distribution, no skewedness, and no kurtosis. 



#========================================================
# iii. granger causality tests
#========================================================

# test if XXXXXXXXXXXXX has no power in explaining YYYYYYYYYYY










